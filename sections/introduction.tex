%% LaTeX2e class for student theses
%% sections/content.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.5, 2024-02-12

\chapter{Introduction}\label{chap:introduction}
The planning and development of large-scale software infrastructures often encompasses software distributed over many different devices,
which may feature vastly different environments for the code running on them.
Especially devices "out in the field" regularly feature architectures very different from the specifications of x86 or ARM,
which makes them very difficult to predict in system simulations or generally in the early planning stages.
Especially when planning real-time systems,
it is very important to plan the communication between IoT devices and the servers running in the backend.
In these scenarios, the backend often runs on x86, or in more recently implemented systems ARM,
while the external devices feature all kinds of different architectures,
that are usually specialized to the task at hand.
Even many IoT devices running ARM cores can often not easily be compared to smartphone- or server-grade ARM.
In addition, when modifying such systems, for example when upgrading hardware,
many of these specialized architectures feature certain behaviors that may be unexpected or not well documented,
which must be addressed when swapping out these physical parts.

In the actual development phase, this issue is already getting solved using emulation.
In the planning phase, especially during design space exploration, where small experiments are already being run,
certain external software is already available, or if the project is a switch of architectures,
like from x86 to ARM in the server world,
emulation could also be used to offer more detailed planning
like for performance criteria.
When a server in a data center is supposed to communicate with an external part that uses pre-developed software,
such an emulation can now be used to produce a good estimate of how performant the server needs to be and how long it should expect to wait for replies.
However, there are issues with emulation, which hinder the use of it in these stages.
The biggest of which is speed, as emulation may result in a slowdown of the factor 1000-10000\cite{slowdown}.
Especially during the exploration of the design space, where only the outline of the project needs to be put down,
such a slowdown is unacceptable, considering the results of the simulation don't need to be exact.

As there are many different emulation environments available,
this thesis chose QEMU, as it is open source and has the most resources available to work with.
The details of the process which led to the selection of QEMU are detailed in \autoref{sec:emulators}.
This thesis tries to generalize findings that may be transferred to other environments,
however as all of these are heavily specialized tools,
the amount of transferrable findings is very limited.

This thesis now introduces the idea of checkpoints to solve this issue of speed and associated resource costs.
The idea is to extract all relevant data from a running emulation
and store it in a generalized way which allows for reusal of the saved state of the system in a different context.
The goal here is to provide a solution with as much flexibility as possible,
meaning a tool which does not require manual tweaking depending on the targeted system.
This especially involves a version-independence in regards to the emulator used.
QEMU has featured the QEMU Human Monitor (QHM) for a long time,
it is however explicitly not meant for processing by other software.
To allow interaction with other software, the QEMU Machine Protocol (QMP) was developed, and the goal is to use this protocol instead,
as the QEMU team tries to keep it somewhat standardized,
while they explicitly write QHM is not stable and there is no guarantee its used formats will be kept consistent,
especially for usages that are not typical for the normal user.
The differences and limitations of both protocols are discussed in detail in \autoref{chap:QEMU_API}.

Initially, this research also aimed to make the development of embedded software easier by using emulation checkpoints to speed up development.
As mentioned before, emulation is very slow.
This of course still applies during development, especially when there is not yet a physical prototype of the developed system available.
To achieve a speedup here, the idea was to make the checkpoints reusable
and create the ability to inject already existing checkpoints back into a running emulation.
This would have even given the option to calculate checkpoints centrally and distribute them,
to save on time and especially resources.
This behavior could not be implemented because of the  limitations of QEMU,
more details on this can be read in \autoref{sec:injection}.
In case someone intends to build up on this and implement the re-injection,
they will find all information regarding such functionality found during this research there.

The theoretical outlines of this thesis including definitions used as well as other works in this field are included in \autoref{chap:Foundations}.
\autoref{chap:QEMU_API} contains both a description of the QEMU APIs according to their official documentation,
however also findings by myself as the official documentation is quite lacking in certain parts, especially the documentation about QHM.
For this reason, it was also decided to make it into its own chapter.
The implementation itself as well as challenges faced during it are mentioned in \autoref{chap:implementation},
and the results of this implementation are discussed and evaluated in \autoref{chap:Evaluation}.
Finally, the works and results of this thesis are concluded in \autoref{chap:Conclusion}.